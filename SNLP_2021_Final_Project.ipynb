{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "101NY1wwGira"
   },
   "source": [
    "## **1 Data Preparation (12 points)**\n",
    "\n",
    "We will use an English corpus that you already know from the assignments (*Alice in Wonderland*), and a Bengali corpus that is decidedly different in both context and language structure. You can find the corpora in `data/bengali_corpus.txt` and `data/alice_in_wonderland.txt`.\n",
    "\n",
    "1. Preprocess both corpora such that they can serve as the input to sentencepiece. (8 points)\n",
    "\n",
    "2. Split the preprocessed corpus into a train and a test set. The test set should comprise 20% of the corpus. Write the two sets to files `train.txt` and `test.txt` (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTx-ofkeKFLQ",
    "outputId": "8c5fde7c-7c8a-40ef-c06e-dca2fcabd190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/snlp-project-21\n",
      "Desktop    Downloads   Music\t Public  sentencepiece\tVideos\n",
      "Documents  miniconda3  Pictures  rnnlm\t Templates\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also `cd` into another directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRODNp4CKFiZ"
   },
   "source": [
    "Alternatively, you can also check the Python API for sentencepiece model training and segmentation and utilise these in your code files.\n",
    "\n",
    "### 2.3 Task\n",
    "\n",
    "You are asked to create data for a language model based on different subword granularity, namely:\n",
    "\n",
    "1. Characters. This can be done manually but also by running BPE with the output vocabulary size being the same as the input alphabet size. (4 points)\n",
    "2. Subword Units: smaller vocabulary, closer to characters. The vocabulary size is usually in the range of 100 to 800 for English. (6 points)\n",
    "3. Subword Units: larger vocabulary, closer to words. The vocabulary size is usually in the range 1500 to 3000 for English. (6 points)\n",
    "\n",
    "In 2 and 3, try to experiment with multiple values and pick one to get the best performance. \n",
    "\n",
    "You should run this on both languages (the train part of the given data), resulting in files: `en_s1.txt`, `en_s2.txt`, `en_s3.txt`, `bn_s1.txt`, `bn_s2.txt` and `bn_s3.txt`.\n",
    "\n",
    "## Take a look at these files and comment briefly on what you observe in terms of word segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTJiQ24YGqJU"
   },
   "source": [
    "## **3 LM Training (20 point)**\n",
    "\n",
    "1. Now, train 3 language models based on the corpora you created in 2.3. We will do this using the RNNLM toolkit. The RNN model is trained on the subword units you have created using SentencePiece. As with all neural models, the performance and computation times depend on the number of hidden layers, backpropagation parameter. The class size is used to implement a class-based language model. <br/>  (8 points)\n",
    "\n",
    "  You can use rnnlm to train a language model with the following command:\n",
    "  ```shell\n",
    "  /home/snlp-project-21/rnnlm/rnnlm \\\n",
    "    -train /path/to/train.txt \\\n",
    "    -valid /path/to/test.txt \\\n",
    "    -rnnlm model \\\n",
    "      -hidden 40 \\\n",
    "      -rand-seed 1 \\\n",
    "      -debug 2 \\\n",
    "      -bptt 3 \\\n",
    "      -class 9999\n",
    "  ```\n",
    "  Remember that you have to prefix it with `!` to run it in the Notebook. \n",
    "\n",
    "  The `model` files will be stored in the same directory as the script. Consider creating a directory to store the models:\n",
    "  ```shell\n",
    "  !rm -rf models/rnnlm \\\n",
    "    && mkdir models/rnnlm \\\n",
    "    && cd models/rnnlm \\\n",
    "    && # call of rnnlm goes here\n",
    "    ...\n",
    "  ```\n",
    "\n",
    "2. After training, the rnnlm toolkit outputs the perplexity of the trained model. Play around with the hyperparameters of rnnlm and report a perplexity that is below the baseline from **3.1**. Use these hyperparamters to train the models you will use in **4.** and **5.**  (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ypmqiARGsaB"
   },
   "source": [
    "## **4 Text Generation (16 points)**\n",
    "\n",
    "After training our language models, we are now ready to create some artificial data! Take a look at the [basic examples](http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz) on the rnnlm site in the folder `~/simple-examples/4-data-generation/test.sh` to find out how to do that (**hint:** it's only a tiny flag!). \n",
    "\n",
    "1. For every language model trained in 3, use rnnlm to generate $k = 10^1, 10^2, 10^3, 10^4, 10^5, 10^6, 10^7$ output tokens. This means that you have to run rnnlm 7 times and change the parameter of the flag in every run. (8 points)\n",
    "\n",
    "  You can use a shell loop to achieve this:\n",
    "  ```shell\n",
    "  for i in {1,2,3,4,5,6,7}; do \\\n",
    "    echo $i; \\\n",
    "    # do something\n",
    "  done\n",
    "  ```\n",
    "  See [here](https://linuxize.com/post/bash-for-loop/) for a detailed introduction. Alternatively, you can implement this in the Python file.\n",
    "\n",
    "2. Save the generated data into text files. You may name them `10.txt`, `100.txt` and so on. Make sure they are saved to different directories for every model. (2 points)\n",
    "  You can redirect the output of a shell comand with `>`:\n",
    "  ```shell\n",
    "  echo 'I am a sample text' > test.txt\n",
    "  ```\n",
    "\n",
    "Note that `>/<` appends to the end of a file. If you want to replace the content of a file use `>>/<<`.\n",
    "\n",
    "3. Inspect `100.txt` for every model. Do you see a difference in the quality of the generated data? Why could that be? <br/>\n",
    "(Note: Your generated data will be in the form of subwords. You have to decode this back to word level to compare) (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYk9s9pZG3YG"
   },
   "source": [
    "## **5 OOV comparison (16 points)**\n",
    "\n",
    "1. Using the original corpora generated in 1., find the train and test vocabulary and determine the OOV rate at word level. Do this by decoding the RNN output, adding all the generated words to your vocabulary and measuring the OOV rate. (2 points)\n",
    "\n",
    "2. Use the generated corpora from **4.** to augment the train vocabulary. Do this $k$ times, i. e. for generated corpora of size $10^1, 10^2,...,10^7$. For each model and each $k$, calculate the OOV rate of the augmented train set against the test set. (8 points)\n",
    "\n",
    "3. For each model, plot OOV rates. What do you observe? Which of the models would you use in a practical application? (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R12ZPsL6oP7j"
   },
   "source": [
    "## **6. Analysis** (20 points)\n",
    "\n",
    "Write a succinct summary of your observations for all the tasks, what you aimed to achieve, and whether your expectations were fulfilled. What are your takeaways from this project? How do your results differ for English and Bengali? What hyperparameters do you use to optimise the OOV rates? Are there any ways you could improve your results?\n",
    "\n",
    "For this section, we will also consider the overall style and how well-written the report is. You should write the summary in the same final Notebook you submit. It should be roughly 500-800 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qNd2rK5xKS8"
   },
   "source": [
    "# 4) Grading\n",
    "\n",
    "The project comprises 25% of the final grade. The grading for this project is distributed as follows:\n",
    "\n",
    "- Data preparation (12 points)\n",
    "- Subword units (16 points)\n",
    "- LM training (20 points)\n",
    "- Text generation (16 points)\n",
    "- OOV comparison (16 points)\n",
    "- Analysis (20 points)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "101NY1wwGira",
    "yRODNp4CKFiZ"
   ],
   "name": "SNLP 2021 Final Project.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
